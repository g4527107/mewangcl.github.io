<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>Highly Parallel Algorithms for Visual Perception Guided Surface Remeshing</title></head><body><center><h1>Highly Parallel Algorithms for Visual Perception Guided Surface Remeshing</h1></center><center>

<a href="#COPYRIGHT">copyright</a> 
<a href="#EXECUTABLES">executables</a> 
<a href="#USAGE">usage</a> 
<a href="#EXAMPLE">example</a> 

</center><hr><a name="COPYRIGHT"><b>COPYRIGHT</b></a> 

<br>All rights about the program are reserved by Lianping Xing, Xiaoting Zhang, Charlie C.L. Wang and Kin-Chuen Hui at the Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong. In no event shall the author be liable to any party for direct, indirect, special, incidental, or consequential damage arising out of the use of this program.<hr><a name="EXECUTABLES"><b>EXECUTABLES</b></a><br>

<a href="http://www2.mae.cuhk.edu.hk/~cwang/pubs/GPURemeshByVisualCues.rar">Download</a>

<br>This program is developed by Visual Studio 2008 together with nVIDIA CUDA SDK 4.2 (<a href="https://developer.nvidia.com/cuda-toolkit-42-archive">Link to CUDA 4.2 download</a>), and an approximate-nearest-neighbour search library - ANN.dll is compiled from the source code provided by David M. Mount and Sunil Arya on the page: <a href="http://www.cs.umd.edu/~mount/ANN/">ANN Library</a>.<br><hr><a name="USAGE"><b>USAGE</b></a><br><ul><dl><dt><b>Step 1) Select menu "File->Import->OBJ Files"</b> : <i>import model</i></dt><dd> --Our system can read data in .obj file formate.<br> </dd><dt><b>Step 2) Select menu "Snapshot->All views"</b> : <i>generate 2D images</i></dt><dd> --The image snaps of an input model is first captured in six orthogonal views.<br></dd><dt><b>Step 3) Select menu "Visual Extraction->Image space"</b> : <i>extract 2D image features</i></dt><dd>--Select menu <b>"Polygon Soup Model"</b> : the perceptual features are then extracted in the image space for the polygon soup model.<br>		     Select menu <b>"2-Manifold Model"</b> : the perceptual features are then extracted in the image space for the orientable 2-manifold model.<br></dd><dt><b>Step 4) Select menu "Visual Extraction->Mapping"</b> : <i>generate 3D saliencies</i></dt><dd>--The perceptual features extracted in the image space are mapped back to R<sup>3</sup> as saliency points.<br></dd><dt><b>Step 5) Select menu "InitSamples"</b> : <i>generate initial samples</i></dt><dd> --The model is first sampled dense points (more or less the number of the vertices of the model). Click "Initial Samples" button and execute the function.<br></dd><dt><b>Step 6) Select menu "Rendering->Adaptive Saliency Map""</b> : <i>build adaptive saliency field</i></dt><dd> --Saliency field is generated and used to govern the adaptive sampling.<br></dd><dt><b>Step 7) Select menu "Num of samples"</b> : <i>generate smaple points</i></dt><dd> --Desired sample points are specified by the user and click "OK".<br></dd><dt><b>Step 8) Select menu "Mesh Operation->Sampling->Adaptive sampling"</b> : <i>execute adaptive sampling</i></dt><dd> --Specified sample points are generated according to the saliency field.<br></dd><dt><b>Step 9) Select menu "Mesh Operation->AWLOP"</b> : <i>optimize sample points</i></dt><dd> --The sample points are optimally positioned by AWLOP operators. Two parameters of AWLOP, <i>h</i> and <i>u</i> can be set, where the value of<i>u</i> is in [0, 0.5) and <i>h = factor*Lavg</i> with <i>Lavg</i> being the average distance between data points to their <i>k</i>−nearest neighbors.Users can set the value of <i>factor</i> to be an integer. By default, it is set to be 2.0.<br></dd><dt><b>Step 10) Select menu "Mesh Operation->Triangulation"</b> : <i>triangulate optimized sample points</i></dt><dd> --Finally, by the optimized samples, a mesh connectivity can be easily reconstructed by using thecomputational geometry techniques (e.g., <a href="http://www.cse.ohio-state.edu/~tamaldey/cocone.html">Tight CoCone</a>). Copy "tcocone.exe" to folder "D:\tcocone".<br></dd><dt><b>Step 11) Select menu "Mesh Operation->Toggle"</b> : <i>toggle results of sample points </i></dt><dd> --The distribution of the initial samples, adaptively generated samples poins and optimized sample points by AWLOP can be interactively displayed.</dd></dl></ul><hr><a name="EXAMPLE"><b>EXAMPLE</b></a><br>For testing purposes, two models are provided:

<li> <a href="http://www2.mae.cuhk.edu.hk/~cwang/pubs/igeaOBJ.rar"><b>Igea</b></a> : A polygon soup model in OBJ file format.</li>


<li> <a href="http://www2.mae.cuhk.edu.hk/~cwang/pubs/kittenOBJ.rar"><b>Kitten</b></a> : A two-manifold model in OBJ file format. This model is originally downloaded from the AIM@SHAPE shape repository.</li><hr><a href="http://www2.mae.cuhk.edu.hk/~cwang">HOME</a></body></html>